---
title: 'G検定勉強メモ'
publishDate: 2025-10-11
tags: ['エンジニアリング']
---

[ディープラーニングG検定（ジェネラリスト）最強の合格テキスト［第2版］](https://www.amazon.co.jp/dp/4815622752/)のメモ。

## ダートマス会議

1956年に開催された会議。主催のジョンマッカーシーが在籍していたのが、ダートマス大学だったらしい。

マービン・ミンスキー、ナサニエル・ロチェスター、クロード・シャノンなども発起人。

## AIブームの変遷

第一次は1950から1960年。明確に定義された特定の問題を解くことはできたが、実用的な利用には程遠く、おもちゃレベルだということでトイプロブレムと呼ばれている。ちなみにイライザが開発されたのは1964年。

第二次は1980年頃。エキスパートシステムと呼ばれる、専門家にヒアリングをして集めた大量の知識をもとに受け答えができるレベル。知識を詰め込むコストが膨大（知識獲得のボトルネック）だったり、例外や矛盾に柔軟に対応するようなことはできず。

エキスパートシステムとしては有機化合物にかんする推論を行うDENDRAL、感染症を扱うMYCIN、緑内障を扱うCASNETなどがある。

第三次は2000年以降、インターネットが普及し、データが爆発的に増え、ビッグデータと呼ばれるようになった。ディープラーニングなどの技術も拍車をかける。

## オントロジー

> オントロジー（ontology）とは、元々は哲学の世界で言う「存在論（存在とは何かを研究する学問）」を示す単語ですが、ITの世界では知識の共有化や再利用の方法として研究開発が進み「対象世界をどの様に捉えた（概念化した）かを記述するもの」という意味で使われています。

引用: [オントロジー（用語解説） :: NTTデータ バリュー・エンジニア-Webサイト](https://www.nttdata-value.co.jp/glossary/ontology)

「人がどのように情報をとらえて理解しているか」ということ自体をコンピュータに理解させるにはどうすればいいか、という考え方。言葉の意味、言葉と言葉の関係性を他人と共有できるように明確なルールに基づいて定義することを重視する。

オントロジーにはヘビーウェイトと、ライトウェイトがある。

*   ライトウェイト: 用語の定義と階層を中心に、最低限の関係だけを持つ。「語彙の共有」「タグ付け・ナビゲーション・検索」をしやすくするための軽量なスキーマ。
    *   「動物 > 犬 > 柴犬」。is-aやpart-ofの関係を定義する
*   ヘビーウェイト: 用語の定義に加え、性質、属性、関係、制約を形式的に記述して機械推論できるレベルまで厳密化したもの。整合性チェックや新しい知識の導出を狙う。
    *   「犬と猫は同じものではない」「人が犬を飼っていれば、その人は飼い主」のような

## 中国語の部屋

チューリングテストに対する有名な反論らしい。チューリングテストに合格したとしても、知能があるとは言えないよね、ということ。

中が見えない部屋から中国語が聞こえてきたとしてもその人は中国語を知っているとは限らない（マニュアルを使って話しているだけで、知識がある、理解しているとは限らない）

## シンボルグラウンディング問題

人間が当たり前にできる「言葉などの記号（シンボル）と、それが指し示す現実世界の対象や概念とを結びつけて意味を理解すること」が、AIにとって難しいという課題。

言葉を言葉で説明するだけだと循環するので、知覚や行為との結びつきが必要。この問題を解決するには、身体性を通じて得られる感覚や経験が必要らしい。

## フレーム問題

問題解決において「何が関係があり、何が無視すべきことか」を自律的に判断できないという、AI研究における本質的な課題。

持ち合わせる知識をすべて使うと、情報量が膨大すぎてフリーズしてしまう。

## 強いAIと弱いAI

弱いAIは特定の仕事に特化したAI。画像認識や翻訳など、決められた範囲で動く。

強いAIは人間のように理解し、さまざまな課題を自律的に解けるAI。一般的な知能（AGI）に近い考え方で、今はまだ実現していない。

現状は、世の中で使われているのはほとんどが弱いAI。ChatGPTなどの大規模言語モデルも弱いAIらしい。言語を中心に多用途だが、人の指示の範囲で動く弱いAI。

強いAIと呼べる目安の例:

*   自律性: 自分で目標を立て、計画して行動できる。
*   一般性: 未知の課題にも柔軟に転用できる。
*   世界との結びつき: 感覚や行為を通じて現実に働きかけ、結果から学べる。

## 機械学習技術の活用イメージ

機械学習はインターネットの普及により、ビッグデータの貯蓄が簡単になった（材料）こと、ハードウェアの性能が向上したこと、アルゴリズムが改善したことで、爆発的に普及し始めた。

### 回帰予測

- 数値をそのまま予測する。
- 例: 売上、在庫切れまでの日数、到着時間、気温。
- 指標: MAEやMAPEなどの誤差を見る。
- メモ: 季節性やトレンドを入れると安定しやすい。ベースライン（平均・前週同曜日）と比較する。

### 分類

- データにラベルを割り振る。
- 例: スパム/非スパム、解約する/しない、不良/良品。
- 指標: 精度だけでなく、適合率・再現率・F1も見る。閾値の調整でバランスを取る。
- メモ: ラベルの偏りが大きい時は重み付けやサンプリングを使う。

### 異常検知

- 「普段と違う」を見つける。ラベルが少ない/ない状況でも使える。
- 例: 機械の振動の異常、アクセスログの不審な動き、売上の急落。
- 方法: 統計的手法、自己符号化器、孤立森林など。
- メモ: アラート数を管理するために、しきい値と通知の運用を先に決める。

## 機械学習の分類

### 教師あり学習

入力と正解（ラベル）の対応を学ぶ。教師あり学習で扱うタスクは主に分類問題と回帰問題。

分類問題は、データをカテゴリやクラスに分けるタスク。例として、メールがスパムかどうか、画像に写っている動物が犬か猫かなどがある。出力は離散的な値（ラベル）になる。

回帰問題は、連続した数値を予測するタスク。例として、明日の気温、来月の売上、家賃の予測などがある。出力は連続的な値（実数）になる。

### 教師なし学習

正解なしでデータの構造や特徴を探すもの。クラスタリングや次元圧縮を使う。用途はセグメンテーション、特徴量作成、異常検知の前処理など。結果の解釈は人が行い、クラスタ数の決め方に工夫がいる。

クラスタリングとは、正解のないデータから共通する特徴を持つグループに分類すること。

代表的な手法はK-means（K平均法）で、以下のようなステップを踏む。

1.   データをランダムにK個のクラスタに分ける
1.   各クラスタの重心を求める
1.   各データと計算された重心の間の距離を計算する
1.   距離が一番近い重心を含むクラスタにデータを割り当て直す
1.   重心の位置が変化しなくなるまで繰り返す

K-meansは非階層クラスター分析の一種で、階層クラスター分析の場合は重心ではなくデータ同士の距離によって、逐次的にクラスタを作っていく。

次元圧縮（次元削減）とは、データを特徴づける情報を抽出すること。

代表的な手法は主成分分析で、強く相関し合う特徴量が多くある状態から、少数の重要な情報を持つ特徴量に情報圧縮を施すのに活用される。

特徴量間の強い相関は過学習を引き起こしやすい（AならBとなりやすくなってしまう）ため、事前に次元削減をしておくと、学習の精度を向上させることができる。

### 半教師あり学習

正解ラベルがついているデータとついていないデータの両方を使う。

正解ラベル付きのデータを十分に用意できない場合や、正解ラベルをつけるコストを削減したい場合などに使う。

### 強化学習

環境で行動し、報酬が最大になるよう学ぶ。状態・行動・報酬・方策が基本要素。

ゲーム、ロボット、在庫や配車の最適化、広告入札などで使われる。

たとえば歩行をロボットに学習させる場合、歩けた距離などを報酬としてフィードバックする。

強化学習の目的は「将来にわたって獲得できる報酬を最大が以下するように行動を学習すること」。

といっても取りうる行動は無数にあり、同じ行動を取ったとしても同じ報酬が得られるとは限らない。そのため、将来もらえる報酬をどれくらい現在の価値として考慮するかを示す「割引率」をパラメータとして設定する。

#### 行動価値関数

行動価値関数（Q関数）は、ある状態で特定の行動を取ったときに、将来得られる報酬の期待値を表す関数。状態と行動の組み合わせに対して、その行動がどれだけ価値があるかを評価する。

最適な行動価値関数を学習することで、各状態で最も価値の高い行動を選べるようになる。Q学習やSARSAなどの手法で、この関数を更新しながら学習を進める。

#### 方策勾配法

方策勾配法は、方策（どの状態でどの行動を取るかの確率分布）を直接最適化する手法。方策をパラメータ化し、報酬の期待値を最大化するように勾配を使って方策のパラメータを更新する。

行動価値関数を経由せずに方策を直接学習できるため、連続的な行動空間や確率的な方策にも適用しやすい。REINFORCEやActor-Criticなどの手法がある。

## バンディットアルゴリズム

複数の選択肢の中から、試行を重ねて平均報酬を最大にする選び方を学ぶ枠組み。各選択肢の報酬の分布は未知で、状態遷移は考えないシンプルな設定。

「活用」はこれまで平均報酬が高い選択肢を選ぶことで、「探索」は情報が少ない選択肢をあえて試して将来の判断精度を上げること。（さらによい方策がないかを探索する）

短期の報酬だけを見ると活用に偏り、真に良い選択肢を見逃しやすい。長期の総報酬を増やすには、活用と探索のバランスを取ることが重要。

例として、ε-greedyは確率ε（イプシロン）で探索し、1−εで現在の最良の選択肢を選ぶ。UCBは推定平均に不確実性のボーナスを加え、情報が足りない選択肢も自然に試す。

応用は、広告クリエイティブの配信比率調整、A/Bテストのトラフィック配分、レコメンドの初期学習などが分かりやすい。

## マルコフ性とマルコフ決定過程モデル

マルコフ性は「未来は現在だけに依存する」という性質。強化学習では、次の状態と報酬は現在の状態と行動で決まり、過去の履歴は見ないと仮定する。

マルコフ決定過程（MDP）はこの仮定の上で環境を表すモデル。状態・行動・遷移確率・報酬・割引率の要素で記述する。

イメージとしては、迷路では、次に移動するマスは今いる位置と選んだ方向で決まる。昨日どの道を通ったかは影響しない、みたいな感じ。

この性質が崩れる = 状態に必要な情報が足りていない可能性があると推測する。

## 特徴量エンジニアリング

機械学習モデルの学習または予測の精度を高めるために、データを加工し、特徴量を作成すること。

*   予測変数として採用する列を選別する
*   データに前処理を施し、学習・予測に効果的な形に加工する
    *   変換（「生年月日」を現時点「年齢」に変換しておくとか、文字列データを数値データに変換するとか、フラグを0と1にするとか）
    *   欠損値の処理
    *   正規化や標準化（平均が0、標準偏差が1になるように変換すること）

男性を1、女性を0というようなデータ自体の大小という性質を持たないデータをカテゴリカルデータという。

春夏秋冬をデータとしてもつ「季節」という列を4列のフラグ列にし、各行について1つの列のみ「1」になるような前処理をOne Hotエンコーディングという。

対して春夏秋冬に対して1,2,3,4のように割り振ることをラベルエンコーディングという。

## 欠損値の扱い方

*   リストワイズ法：データをそのまま削除する。総データ量が多い場合に使いやすい。欠損自体になんらかの傾向がある場合に削除すると、データ自体の傾向を変化させてしまうリスクもある
*   統計量で補完：欠損になっていないデータだけを使って、平均、中央値、最頻値などを算出し補うやり方
*   回帰補完：欠損列と非欠損列に相関がある場合に、回帰を利用して、埋める。非欠損データを利用して、補充値を推測するモデルを作る。

## ノーフリーランチ定理

> あらゆる問題において、高い精度を出せる汎用的なモデルは存在しない

## 過学習

学習データを過剰に学習することで、モデルを学習データに合わせすぎてしまい、未知のデータに対する汎用性が失われてしまっている状況を指す。オーバーフィッティング、過剰適合ともいう。

*   学習データでは精度がよいのに、未知の本番データでは精度が悪くなる。
*   データ数が少ないのに、特徴量の数が多い
*   相関が多い特徴量が多い
*   モデルが複雑すぎる（高次元の関数になっている）
*   モデルのパラメータの値が大きすぎる

対策としては以下が考えられる。

*   学習データの数を増やす（偏りがない方が望ましい）
*   ハイパーパラメータを調整することで、複雑さを抑える
*   正則化を実施する
*   決定木のアンサンブル学習器を活用する

### バイアスとバリアンス

バイアスは、モデルの平均的な予測と、真の目標値（データ生成過程が与える期待値）の差のこと。モデルが単純すぎるとこの差が大きくなり、学習後も予測と正解の間の誤差（損失）が高止まりする。これがアンダーフィット。

バリアンスは、訓練データを入れ替えたときにモデルの予測がどれだけ変わるかという、ばらつきの大きさのこと。モデルが複雑すぎると、訓練データ上では損失が小さい／分類が正解するが、検証・テストデータ上では損失が大きい／誤分類が増える状態になりやすい。これがオーバーフィット。

バイアスが小さく、バリアンスが大きい状態だと過学習になりやすい。

## 線形回帰

線形回帰とは、1つ以上の説明変数と直線関数を使用して、連続値である目的変数を予測する手法。

### 単回帰分析

説明変数が1つだけある線形回帰のこと。

```math
Y = aX+b
```

Xが説明変数で、Yは目的変数、aとbは回帰係数という。aは目的変数Yに対する説明変数Xの影響度を表す。

例: X軸に1日の平均湿度をとり、Y軸の値に当たる洗濯物が乾くまでの時間を予測するタスクは、単回帰分析になる。

### 重回帰分析

説明変数が2つ以上ある線形回帰のこと。

```math
\hat{y}_i=a_1 x_{1,i}+a_2 x_{2,i}+...+b
```

x_iが説明変数で、y_iは目的変数、a_iは偏回帰係数と呼ばれ、各説明変数の予測したい量への影響度を表しているため、偏回帰係数の大小を比較することで、どの変数が予測に重要なのかという目安を得ることができる。

例: 1日の平均湿度と風速の2つの説明変数から、洗濯物が乾くまでの時間（Y）を予測する。

相関が高い説明変数同士を特徴量として組み合わせたときに互いに干渉し精度を悪くしてしまう現象を多重共線性（Multicollinearity）という。

変数同士の相関係数を計算した結果、相関係数が1または-1に近い場合に相関が高いという。

## 損失関数

モデルの予測と正解の差を数値化する関数。モデルの学習とは、この関数の値が最小になるように係数（パラメータ）を調整することを指す。

損失関数は予測値と正解値を入力に取り、係数の値に依存して変わる。つまりモデルの良し悪しを数値化したもの。

重回帰分析の予測値を

```math
\hat{y}=a_1 x_1+a_2 x_2+b
```

とした時、損失関数は、

```math
E(a_1,a_2,b)=\frac{1}{N}\sum_{i=1}^{N}(y_i-\hat{y}_i)^2 \quad\text{(平均二乗誤差)}
```

のように、関数式の中に予測値を含む。実際の最適化では、上の損失 E に正則化項を足した J(ω) を最小化する。回帰では平均二乗誤差（MSE）、分類では交差エントロピー損失をよく使う。

損失関数は、解決したい問題によって使い分けられる。

*   回帰問題：平均二乗誤差関数
*   バイナリ分離問題：交差エントロピー誤差関数
*   多クラス分類問題：多クラス交差エントロピー誤差関数

### 最小二乗法

実測値と予測値のズレが最も小さくなるようにモデルのパラメータを決める方法。

たとえば以下のようなデータがあった場合

```math
(x_1,y_1),(x_2,y_2),...,(x_n,y_n)
```

これらの点にできるだけ近い直線を求める。

```math
\hat{y}=\beta_0+\beta_1x
```

## 正則化（Regularization）

損失関数に、係数（重み）に対してのみ罰則の項（正則化項）を加える。これは切片（オフセット値）には通常適用せず、重みが過大になるのを防ぐための仕組み。

### 損失関数と正則化の関係

学習で最小化するのは「データに対する損失」そのものではなく、「損失＋正則化項」を足し合わせた目的関数である。

```math
J(\omega)=E(\omega)+\lambda R(\omega)
```

ここで、

*   E：データに対する損失（例：平均二乗誤差 MSE）
*   R：係数の大きさに対する罰（例：L1/L2 ノルム）
*   λ：罰の強さ（正則化の重み）

Eは当て方のズレを減らし、Rはモデルの複雑さを抑える。正則化項Rは一般的には以下のような形になる。

```math
\lambda\sum_{i}|\omega_i|^p
```

### L1正則化

正則化項Rを`p=1`、つまりパラメータの絶対値の和をペナルティ項にする。不要なパラメータを落とすことで、特徴選択と次元圧縮の効果がある。

L1正則化を取り入れた線形回帰はラッソ回帰と呼ばれる。

### L2正則化

正則化項Rを`p=2`、つまりパラメータの絶対値の二乗和をペナルティ項にする。パラメータの大きさをゼロに近づける（影響を小さく抑える）ことで、汎用性の高い滑らかなモデルが得られ、過学習防止に効果的。

L2正則化を取り入れた線形回帰をリッジ回帰と呼ぶ。

ラッソ回帰とリッジ回帰を組み合わせた手法をElastic Netと呼ぶ。

## パーセプトロン

パーセプトロンは、線形分離可能なデータを分類するための基本的なアルゴリズム。入力に重みをかけて合計し、閾値を超えたら1、超えなかったら0を出力する。

単純パーセプトロン（単層パーセプトロン）は基本的に二値分類（2クラス分類）に使われる。1つのパーセプトロンは1つの線形分離面を作るため、マルチクラス分類には直接使えない。

マルチクラス分類に拡張する方法として、One-vs-Rest（各クラスごとに「そのクラス vs それ以外」で分類）やOne-vs-One（クラスのペアごとに分類して多数決）がある。多層パーセプトロンでは、出力層のニューロン数をクラス数に合わせることでマルチクラス分類が可能になる。

## 活性化関数

活性化関数は、ニューロンやパーセプトロンの入力の重み付き和を非線形変換する関数。

主な役割は、非線形性の導入。線形変換だけでは表現できない複雑なパターンを学習できるようにする。多層のニューラルネットワークでは、活性化関数がないと何層重ねても線形変換の組み合わせにしかならず、表現力が上がらない。他にも、出力範囲の制限（0から1の範囲に収めるなど）、勾配の制御（学習の効率を上げる）、スパース性の導入（一部のニューロンだけを活性化させる）などの役割がある。

パーセプトロンでは、閾値を超えたら1、超えなかったら0を出力するステップ関数が使われる。ニューラルネットワークでは、シグモイド関数やReLU関数などがよく使われる。シグモイド関数は0から1の範囲に値を収め、確率的な解釈がしやすい。ReLU関数は負の値を0にし、正の値はそのまま通す。勾配消失問題を緩和し、学習が速くなる。

シグモイド関数は入力値が小さい/大きい場合、出力が平らになる性質を持っているため、それが勾配消失問題につながっていた。

### ReLU関数

勾配消失問題に対応するため活性化関数としてReLU関数が使われるようになった。

ReLU関数は入力値が負の値なら0、正の値であれば入力値をそのまま返す。負の入力値をノイズとして取り除くことで、特徴を際立たせることができる。

## ロジスティック回帰分析

ロジスティック回帰分析はある事象が発生する確率を求める非線形回帰の手法。線形回帰と同様な考え方をクラス分類問題に応用し「ユーザーのデータを関数に与えた結果が0.5以上であれば購買者と判定する」のような使い方をする。

分類するカテゴリが2つである二値分類と、3つ以上であるマルチクラス分類の両方に適用できる。

二値分類に使う関数はシグモイド関数（どんな数値を入力しても、出力が0から1になるようなS字型の滑らかな曲線を描く関数）であり、一般的なシグモイド関数は以下のような式で表される。

```math
f(x)=\frac{1}{1+e^{-x}}
```

※ eはオイラー数（≈ 2.71828）

0.5などの閾値を決めることで、結果が0.5未満か、0.5以上かにより分類ができる。確率は0から1の範囲に収めるのが基本。

説明変数がn個ある場合の式は以下のようになる。

```math
f(x)=\frac{1}{1+e^{-({a_1}{x_1}+{a_2}{x_2}+...+{a_n}{x_n})}}
```

xはどんな値であっても、分母は必ず1より大きい値になるため、f(x)の値は0から1の範囲に収まることになる。

分類問題におけるロジスティック回帰は、係数の大小が予測対象への影響度を表すので比較的解釈しやすいという利点がある。

## サポートベクトルマシン

犬か猫か、スパムメールかなどの分類問題でよく使われる手法。

複数の特徴量で区別された2つのクラスに分かれたデータが平面上に分布しているときに、クラスの境界線を引く。

そのとき境界線に一番近いデータをサポートベクトルと言い、境界線とサポートベクトルの距離（マージン）を最大化しつつ、正しく分類できる最適なバランスをとることで、未知のデータが入力されたときにもそのデータがどのクラスに分類されるかを正しく予測できる。これを汎化性能という。

全てのデータを完全に分類するが、外れ値に弱いハードマージンSVMと、誤差を許容しつつ分類性能を高めるソフトマージンSVMがある。ソフトマージンではマージン内にデータが入ることを許容する（どの程度入っていいかを調整する）。

### カーネル関数

SVMの基本形は線形分離だが、現実的に一本の直線で綺麗に分類できることは少ない。そこでSVMでは以下のような処理を行う。

1.  データを高次元に写像する
2.  高次元空間で線形分離する
3.  その結果を元の次元空間に投影して境界を得る

この処理に使われるのがカーネル関数。いくつかの種類がある。以下はRBF（ガウシアン）カーネル

```math
K(x,x^\prime) = exp(-\gamma\|x-x^\prime\|^2)
```

SVMの決定関数は次の形をしている。

```math
f(x) = \sum_{i}a_iy_iK(x_i,x)+b
```

ここで`K(x_i,x)`がカーネル関数を示す。

## 決定木

データをできるだけうまく分類できるように特徴量を設定し木を作っていくやり方。スパムメールの分類や、家賃・株価予測などにも利用できる。

1.  天気は晴れか？
    1.  「いいえ」なら「外出しない」
    1.  「はい」なら次へ
1.  気温は高いか？
    1.  「はい」なら「外出しない」
    1.  「いいえ」なら外出する

ここで天気や気温が特徴量であり、その特徴量に基づいて最終的に予測結果を得るのが目的である。

決定木は柔軟で理解しやすい一方で、過学習しやすいため、木の深さを制限したり、分割の最小データ数を設定するなどの工夫が必要になる。

## アンサンブル学習器

単独では精度が高くない単純なモデルを多数組み合わせて使うことで精度を改善する手法。アンサンブル学習にはバギングとブースティングというアプローチがある。

*   バギング：少しずつ異なる学習器を多数作り、それらを並列に学習させ、結果を統合する
    *   例：ランダムフォレスト
*   ブースティング：多数の学習器を1つずつ逐次的に構築する過程で、前に構築された学習器の結果を利用する
    *   例：勾配ブースティング回帰木

## 不純度

機械学習における不純度とは、決定木の分割基準として使われる指標のこと。ノード内のデータがどのくらい異なるクラスに混ざっているかを表す。

不純度が低いほど、そのノードは1つのクラスに偏っている（純粋）。不純度が高いほど、複数のクラスが混在している。決定木は、分割によって不純度が最も下がる特徴量と閾値を選んで木を成長させる。

主な不純度の指標には、ジニ不純度とエントロピーがある。どちらも、ノード内のクラス分布が偏っているほど値が小さくなる。

## ナイーブベイズ

単語間の相関は考慮せず、出現頻度にのみ着目して分類を行う手法。

## K近傍法

特徴量空間上にすべての学習済みデータをプロットし、未知のデータをその空間にプロットした際、最も近い距離にある点を見つけて、多数決を取り、もっとも多い所属クラスに分類する。

距離を計算する関数にもいろいろあるらしい。いくつの点で多数決を取るか（= K）によって結果が変わる。

## 訓練データとテストデータの分割

学習データは訓練に使うための特徴量+正解をセットにした訓練データと、評価用に特徴量だけにしたテストデータの2種類に分割される。

学習データを分割する手法として代表的なのが、ホールドアウト法と、交差検証法。

ホールドアウト法は単純にモデル構築に使えるデータを指定の割合（8:2など）で分割する方法。データ量が少なく、偏りが起きるとうまくいかない。

交差検証法は精度評価を複数回行う前提でデータを分ける。

1.  データをいくつかのグループにランダムに分ける
1.  1つのグループをテスト用データ、他を訓練用データとして訓練と評価を行う
1.  別のグループをテスト用データとして、再度訓練と評価を行う

## 精度評価

シンプルに書くと、以下のような対応表ができる。

| | 予測結果が0 | 予測結果が1 |
|---|---|---|---|
| 正解が0 | 真陰性（TN） | 偽陽性（FP） |
| 正解が1 | 偽陰性（FN） | 真陽性（TP） |

それぞれの件数をもとに、以下のスコアを算出する。

Accuracy（正解率）：

```math
\frac{TP + TN}{TP + TN + FP + FN}
```

Precision（適合率）：

```math
\frac{TP}{TP + FP}
```

Recall（再現率）：

```math
\frac{TP}{TP + FN}
```

F-measure（F値）：

```math
\frac{2 \times Precision \times Recall}{Precision + Recall}
```

## ニューラルネットワークの学習プロセス

### 勾配降下法

勾配降下法は重みの値を最適化するための手法。

出力と正解の誤差を定量的に表すために、損失関数を用いる。簡単に言えば、この損失関数の結果が最小化するようにパラメータを調整することになる。

しかし、結果を最小化するためにはパラメータを調整した後の損失関数の値が大きくなったのか、小さくなったのか、つまり傾きを求める（= 微分する）必要がある。誤差が減る方向（損失関数の傾きが負になる方向）にパラメータを更新する。勾配が下がるから勾配降下法。

パラメータを変更した後、一時的に勾配が上がる場合があるが、勾配が上がったからといって、その時点でのパラメータが最適解とは言えないこともある。

#### プラトー

プラトーは、学習過程で損失関数の値がほとんど変化しない平坦な期間のこと。勾配がほぼ0になり、学習が停滞している状態を指す。

局所最適解に到達した場合や、学習率が小さすぎる場合、データが不足している場合などに起こりやすい。プラトーから抜け出す方法として、学習率（重みを更新する幅）の調整、モメンタムの導入、異なる初期値での再学習などがある。

#### 確率的勾配降下法

通常の勾配降下法（最急降下法）は、全データを使って勾配を計算してからパラメータを更新する。学習の結果が安定しやすいが、データ量が大きいと計算コストが高くなる。

オンライン学習は、1つのサンプルだけを使って勾配を計算し、すぐにパラメータを更新する。全データを使わないため計算が速く、ノイズがあることで局所最適解から抜け出しやすくなるが、外れ値に敏感であり、学習が安定しない。

ミニバッチ勾配降下法は、小さなバッチ（例：32個、64個）のサンプルを使って勾配を計算する。最急降下法とオンライン学習の中間的な手法で、計算効率と安定性のバランスが良い。


### 誤差逆伝播法

誤差逆伝播法は重みを更新するために必要な誤差情報をネットワーク内で伝達する方法。

通常、入力値は隠れ層を通って出力へと向かう（順伝播）が、誤差は出力層から入力層へ戻す必要がある。

## 畳み込みニューラルネットワーク（CNN）

畳み込みニューラルネットワーク（CNN）は、画像認識に特化したニューラルネットワーク。通常の全結合層とは異なり、畳み込み層やプーリング層などの特殊な層を持つ。

畳み込み層は、フィルタ（カーネル）と呼ばれる画像を使って、入力画像の局所的な特徴を抽出し、エッジやテクスチャなどの小さなパターンを検出する。フィルタと入力画像の間では畳み込み演算が行われ、算出された特徴表現を含む特徴マップが次の層に渡されより高次の特徴抽出を行う。

プーリング層は、特徴マップのサイズを縮小し、主要な特徴を維持しながら、位置のずれに対して頑健にする。

画像の一部が移動しても同じ特徴として認識できる位置不変性を持つのが特徴。画像分類、物体検出、セグメンテーションなどに使われる。

### CNNに関連する技術

重みの初期設定法や、量子化、プリーニング、蒸留などによるモデルの軽量化などの他にも、

*   ドロップアウト：一部のニューロンをランダムに無効化することで、過学習を抑える
*   バッチ正規化：ミニバッチごとにm、各層への入力データを標準化
*   データ拡張：回転や並行移動をすることで、人工的に訓練画像のバリエーションを増やす
*   転移学習：膨大なデータで訓練sヒィたモデルを別のタスクに転用・応用する

## リカレントニューラルネットワーク（RNN）

リカレントニューラルネットワーク（RNN）は、時系列データや自然言語などの順序を持つデータ（順序が重要であるデータ）を扱うためのニューラルネットワーク。過去の情報を内部状態として保持し、次の出力に反映させるフィードバックループを持つ。

通常のニューラルネットワークは、各入力が独立に処理される。RNNは、前のステップ（時刻）の出力を次のステップ（時刻）の入力として使うフィードバック構造により、時系列の依存関係を学習できる。ここで「時刻」とは、時系列データの各位置（ステップ）を指す。時間的なデータだけでなく、文章の各単語の位置など、順序を持つデータの各要素も「時刻」と呼ぶ。

自然言語処理、音声認識、機械翻訳などに使われる。ただし、長い時系列では勾配消失問題が起こりやすく、長期的な依存関係を学習しにくい。

### 重み衝突問題

通常のニューラルネットワークでは、予測したいものと関係が深いデータが入力された場合は重みが大きく、関係が薄いデータは重みが小さくなる。これは一般的には変化しづらいものである。

一方、時系列データでは、各ステップ（時刻）によって、同じ特徴量でも重要度が変わる。特定のステップでは重みが小さいが、別のステップでは重みが大きくなる、というようなことが起きる。例えば、文章では文脈によって同じ単語でも重要度が変わる。

この問題を解決するために、入力ゲート、出力ゲート、忘却ゲートのゲート構造を新たに設けるLSTM（Long Short Term Memory）や、LSTMをさあらに簡略化したGRU（Gated Recurrent Unit）などの改良版が開発されている。GRUではリセットゲート、更新ゲートの2種類が使われる。
