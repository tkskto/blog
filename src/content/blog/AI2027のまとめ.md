---
title: 'AI2027のまとめ'
publishDate: 2026-01-11
tags: ['エンジニアリング']
---

[AI 2027](https://ai-2027.com)のまとめ。正直よくわからないことが多いので、あまり鵜呑みにしはしていない。

後半にいくにつれて、遠い未来の話感が増すので、未来予測ではなく技術者などがどんな恐れを抱き始めているかを寓話にしたものとして読むようにした。

いっぽうで、本当にこのような世界が来た時に、誰が、どの立場で、どんな選択肢を検討しなくてはいけないのか、という点では参考になるのかもしれない。

## March 2027までのまとめ

### AI開発競争の重心が「モデル性能」から「研究加速能力」へ移っている

AIを賢くする能力そのものが競争力になっており、単なるプロダクトAIの導入では差がつきにくい。日本企業が「AIを使う側」に留まる場合、構造的に不利になる可能性が高い。

### 計算資源（データセンター・電力）の国家戦略的重要性が急上昇している

巨大データセンターと電力確保が前提条件になっている。日本は電力制約・立地制約が厳しく、国内完結型での競争は難易度が高い。

### アルゴリズムとモデル重みが「国家機密級の資産」になりつつある

重みの窃取が国家安全保障問題として扱われている。日本企業・研究機関においても、AIモデルや学習成果を「情報資産」としてどう守るかが問われる。

### オープン vs クローズドの議論が、安全保障と直結するフェーズに入っている

オープンウェイトは技術民主化の一方で、国家間競争ではリスク要因にもなる。日本がどの立場を取るのか（追随・中立・橋渡し役）は未整理。

### AIによる研究・開発の自動化が「人材像」を根本から変える

ジュニア層の価値が下がり、「AIを管理・評価・統合できる人材」に価値が集中する。日本の年功序列・育成前提モデルと強く衝突する。

### ソフトウェア産業だけでなく、製造業・研究開発全体に波及する

コーディング自動化は一例で、本質は「知的労働の分解と再構成」。日本の強みである製造業R&Dも例外ではない。

### アラインメントや安全性は「未解決のまま進む」前提で考える必要がある

安全性が完全に解決されてから社会実装される、という前提は成立していない。日本の規制・合意形成プロセスはスピード面で課題が出やすい。

### 「使うかどうか」ではなく「どこまで依存するか」が論点になっている

AIを業務効率化ツールとして使う段階はすでに通過点。意思決定・研究・設計にどこまで委ねるか、というガバナンスの問題に移行している。

### 同盟国（特に米国）との距離感が、そのまま技術アクセス格差になる

最先端モデルは一部政府・企業にのみ共有される構図が描かれている。日本が「情報をもらえる側」に入れるかどうかは外交・安全保障とも連動する。

### 時間軸が極端に短い（数年単位）

10年スパンのDXや人材育成計画では間に合わない可能性が高い。2〜3年での組織設計・投資判断が問われる。

## Webやソフトウェア開発業界への影響

少し深掘りしてもらった。

### 「実装力」の価値は急速に下がり、「設計・分解・評価」の価値が上がる

HTML/CSS/JSを書く、APIを実装する、といった作業はほぼ完全に自動化される。価値が残るのは、要件を正しく分解し、AIに渡し、出てきた成果物を評価・修正できる力。

### ジュニア〜ミドル層の役割が消失しやすい

「指示されたものを実装する人」は、Agent-3級のコーダーに置き換わる。人材育成を前提にしたピラミッド構造は成立しにくくなる。

### シニアエンジニアの役割は「手を動かす人」から「AIチームのマネージャー」へ

コードを書く時間より、「どこをAIに任せるか」「どう検証するか」「どこで止めるか」を判断する時間が支配的になる。

### レビュー工程が最大のボトルネックになる

生成スピードが上がるほど、人間が読む・考える工程が詰まる。テスト、Lint、型、安全性チェックなど「機械的に検証できる設計」が必須条件になる。

### アーキテクチャ・設計思想の差が、そのまま生産性差になる

疎結合、明確な責務分離、契約（型・スキーマ）があるコードベースほどAIと相性が良い。逆に、属人化・暗黙知だらけのプロジェクトはAI導入の効果が出ない。

### 「コードを書く」より「環境を作る」仕事が増える

CI/CD、テスト自動化、AI用のプロンプト・ガードレール、レビュー基準づくりなど、AIが暴走しないための“足場づくり”が本業になる。

### Web制作の見積モデルが崩れる

ページ数・画面数・工数ベースの見積は意味を失う。価値の源泉は「設計品質」「再利用性」「運用コスト削減」「安全性」に移る。

IA、コンポーネント分割、CMSスキーマ、API設計、権限設計、運用フロー、これらを「作業過程」ではなく「納品物」として契約に載せる。

ボリュームではなく、設計難易度、構造の複雑さ、運用期間中の変更耐性を見積の軸にする準備が必要

### 受託開発と内製の境界が曖昧になる

AIが即席で「社内チーム」を作れるため、発注側が内製化しやすくなる。制作会社は「人手の代替」ではなく「設計・ガバナンス提供」に寄らないと厳しい。

### フロントエンドは“最後まで人が触る領域”ではなくなる

アクセシビリティ、UX微調整、ブランド表現などは残るが、「実装作業」はAIの主戦場になる。

### CMS・バックエンド設計の重要性が跳ね上がる

AIが安全に触れる境界（BFF、API、CMSスキーマ）が曖昧だと事故が起きる。「どこまでAIが触っていいか」を前提にした設計が必須になる。

BFF、CMS、管理画面、CI/CD。「ここまではAI可、ここからは人間のみ」という境界設計を社内標準にする。

CMS設計は「入力UI」ではなく「安全装置」として扱う。フィールド設計、権限、公開フローは、AI事故を防ぐための制御点。CMS設計者の役割を再定義する。

### セキュリティ・責任分界が経営課題になる

AIが書いたコードの責任は誰が負うのか。脆弱性混入・ライセンス違反・データ漏洩への説明責任をどう担保するかが、技術問題ではなく経営問題になる。

### 「AIが使える人」では差がつかない

全員がAIを使える前提になる。差が出るのは「AIに任せない判断ができるか」「間違いに気づけるか」「設計で事故を未然に防げるか」。

### 学習内容が根本的に変わる

新しいフレームワークより、抽象化、境界設計、テスト設計、レビュー技法、リスク思考が重要になる。

AI生成物を前提にすると、テストやレビューは付随作業ではなく主作業になる。レビュー基準、テスト観点、NG例を明文化する。

「簡単な実装から始める」若手育成モデルは成立しない。レビュー、設計補助、テスト設計から入る育成モデルに切り替える。

### Web制作会社の差別化軸が再定義される

「作れます」ではなく、「壊れない」「安全」「長く運用できる」「AI前提でも破綻しない」を説明できる会社が生き残る。

### 技術リード／テックリード個人のスキル再定義

*   書く人から、決める人へ
    *   自分で実装できることより、「誰（AI/人）に何をやらせるか」を決める能力が中心になる。
*   要件分解力が最重要スキルになる
    *   曖昧な要求を判断可能、テスト可能、AIに渡せる単位に分解できるかどうか。
*   レビュー能力が実装能力を上回る
    *   「正しいか」「危ないか」「今はOKだが将来壊れるか」を見抜く力。コードを速く書けることより重要になる。
*   設計を言語化できること
    *   なぜこの構造なのか、なぜこの境界なのかを非エンジニアにも説明できること。
*   AIの失敗パターンを知っている
    *   ハルシネーション、過剰最適化、境界無視。AIを信用しすぎない勘所が必要。
*   「任せない判断」ができる
    *   全部AIにやらせない。法務・セキュリティ・UX・ブランド表現など、人が握る領域を決められる。
*   技術選定より構造選定
    *   フレームワーク比較より、構造がシンプルか、責務が分離されているか、変更に耐えるかを見る。
*   テストとガードレールを設計できる
    *   AIの出力を前提にしたテスト設計、CI/CD、静的解析を組み立てられる。
*   チームの不安を言語化できる
    *   「仕事がなくなるのでは」という空気に対し、現実的な役割変化を説明できる。
*   学び直しの軸を変える
    *   新ライブラリより、抽象化、設計原則、リスク思考、責任分界に時間を使う。
